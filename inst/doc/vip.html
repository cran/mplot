<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Variable inclusion plots</title>






<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Variable inclusion plots</h1>



<blockquote>
<p>Overview of variable inclusion plots.</p>
</blockquote>
<p>Rather than visualising a loss measure against model size, it can be instructive to consider which variables are present in the overall <em>best</em> model over a set of bootstrap replications. To facilitate comparison between models of different sizes we use the generalised information criterion,</p>
<p><span class="math display">\[\textrm{GIC}(\alpha,\lambda) = \hat{Q}(\alpha) + \lambda p_{\alpha}.\]</span></p>
<p>The <span class="math inline">\(\hat{Q}(\alpha)\)</span> component is a measure of <em>description loss</em> or <em>lack of fit</em>, a function that describes how well a model fits the data, for example, the residual sum of squares or <span class="math inline">\(-2~\times~\text{log-likelihood}\)</span>. The number of independent regression model parameters, <span class="math inline">\(p_{\alpha}\)</span>, is a measure of <em>model complexity</em>. The penalty multiplier, <span class="math inline">\(\lambda\)</span>, determines the properties of the model selection criterion <span class="citation">(Müller &amp; Welsh, 2010; Müller et al., 2013)</span>. Special cases, when <span class="math inline">\(\hat{Q}(\alpha)=-2\times\text{log-likelihood}(\alpha)\)</span>, include the AIC with <span class="math inline">\(\lambda=2\)</span>, BIC with <span class="math inline">\(\lambda=\log(n)\)</span> and more generally the generalised information criterion (GIC) with <span class="math inline">\(\lambda\in\mathbb{R}\)</span> <span class="citation">(Konishi &amp; Kitagawa, 1996)</span>.</p>
<p>Using the same exponential weighted bootstrap replications as in the model selection plots, we have a set of <span class="math inline">\(B\)</span> bootstrap replications and for each model size we know which model has the smallest description loss. This information is used to determine which model minimises the GIC over a range of values of the penalty parameter, <span class="math inline">\(\lambda\)</span>, in each bootstrap sample. For each value of <span class="math inline">\(\lambda\)</span>, we extract the variables present in the <em>best</em> models over the <span class="math inline">\(B\)</span> bootstrap replications and calculate the corresponding bootstrap probabilities that a given variable is present. These calculations are visualised in a variable inclusion plot (VIP) as introduced by <span class="citation">Müller &amp; Welsh (2010)</span> and <span class="citation">Murray et al. (2013)</span>. The VIP shows empirical inclusion probabilities as a function of the penalty multiplier <span class="math inline">\(\lambda\)</span>. The probabilities are calculated by observing how often each variable is retained in <span class="math inline">\(B\)</span> exponential weighted bootstrap replications. Specifically, for each bootstrap sample <span class="math inline">\(b=1,\ldots,B\)</span> and each penalty multiplier <span class="math inline">\(\lambda\)</span>, the chosen model, <span class="math inline">\(\hat{\alpha}_{\lambda}^{b}\in \mathcal{A}\)</span>, is that which achieves the smallest <span class="math inline">\(\textrm{GIC}(\alpha,\lambda;\mathbf{w}_b) = \hat{Q}^b(\alpha)+\lambda p_{\alpha}\)</span>, where <span class="math inline">\(\mathbf{w}_b\)</span> is the <span class="math inline">\(n\)</span>-vector of independent and identically distributed exponential weights. The inclusion probability for variable <span class="math inline">\(x_{j}\)</span> is estimated by <span class="math inline">\(B^{-1}\sum_{i=1}^{B}\mathbb{I}\{j\in \hat{\alpha}_{\lambda}^{b}\}\)</span>, where <span class="math inline">\(\mathbb{I}\{j\in \hat{\alpha}_{\lambda}^{b}\}\)</span> is one if <span class="math inline">\(x_{j}\)</span> is in the final model and zero otherwise. Following <span class="citation">Murray et al. (2013)</span>, the default range of <span class="math inline">\(\lambda\)</span> values is <span class="math inline">\(\lambda\in[0,2\log(n)]\)</span> as this includes most standard values used for the penalty parameter.</p>
<p>The example shown in the bottom panel of <a href="msp#fig:plotvis">this figure</a> is obtained using the <code>which = &quot;vip&quot;</code> argument to the plot function. As expected, when the penalty parameter is equal to zero, all variables are included in the model; the full model achieves the lowest description loss, and hence minimises the GIC when there is no penalisation. As the penalty parameter increases, the inclusion probabilities for individual variables typically decrease as more parsimonious models are preferred. In the present example, the inclusion probabilities for the <span class="math inline">\(x_8\)</span> variable exhibit a sharp decrease at low levels of the penalty parameter, but then increase steadily as a more parsimonious model is sought. This pattern helps to explain why stepwise model selection chose the larger model with all the variables except <span class="math inline">\(x_8\)</span> – there exists a local minimum. Hence, for large models the inclusion of <span class="math inline">\(x_8\)</span> adds no additional value over having all the other explanatory variables in the model.</p>
<p>It is often instructive to visualise how the inclusion probabilities change over the range of penalty parameters. The ordering of the variables in the legend corresponds to their average inclusion probability over the whole range of penalty values. We have also added an independent standard Gaussian random variable to the model matrix as a redundant variable (<code>RV</code>). This provides a baseline to help determine which inclusion probabilities are <em>significant</em> in the sense that they exhibit a different behaviour to the <code>RV</code> curve. Variables with inclusion probabilities near or below the <code>RV</code> curve can be considered to have been included by chance.</p>
<p>To summarise, VIPs continue the model stability theme. Rather than simply using a single penalty parameter associated with a particular information criterion, for example the AIC with <span class="math inline">\(\lambda=2\)</span>, our implementation of VIPs adds considerable value by allowing us to learn from a range of penalty parameters. Furthermore, we are able to see which variables are most often included over a number of bootstrap samples.</p>
<div id="references" class="section level4 unnumbered">
<h4>References</h4>
<div id="refs" class="references">
<div id="ref-Konishi:1996">
<p>Konishi, S., &amp; Kitagawa, G. (1996). Generalised information criteria in model selection. <em>Biometrika</em>, 83(4), 875–890. DOI:<a href="https://doi.org/10.1093/biomet/83.4.875">10.1093/biomet/83.4.875</a></p>
</div>
<div id="ref-Murray:2013">
<p>Murray, K., Heritier, S., &amp; Müller, S. (2013). Graphical tools for model selection in generalized linear models. <em>Statistics in Medicine</em>, 32(25), 4438–4451. DOI:<a href="https://doi.org/10.1002/sim.5855">10.1002/sim.5855</a></p>
</div>
<div id="ref-Mueller:2010">
<p>Müller, S., &amp; Welsh, A. H. (2010). On model selection curves. <em>International Statistical Review</em>, 78(2), 240–256. DOI:<a href="https://doi.org/10.1111/j.1751-5823.2010.00108.x">10.1111/j.1751-5823.2010.00108.x</a></p>
</div>
<div id="ref-Mueller:2013">
<p>Müller, S., Scealy, J. L., &amp; Welsh, A. H. (2013). Model selection in linear mixed models. <em>Statistical Science</em>, 28(2), 135–167. DOI:<a href="https://doi.org/10.1214/12-STS410">10.1214/12-STS410</a></p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
